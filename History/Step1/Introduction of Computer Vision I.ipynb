{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overhead-donor",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lined-fever",
   "metadata": {},
   "source": [
    "![](https://images.velog.io/images/qsdcfd/post/1f4fe63c-c5ee-4a72-abc0-94004371af53/image.png)\n",
    "\n",
    "[저자: Simplilearn]\n",
    "\n",
    "[이미지 출처:[링크텍스트](https://www.simplilearn.com/computer-vision-article)]\n",
    "\n",
    "사실 컴퓨터비전을 처음 공부하는 페이지에서 다양한 기술적 용어로 바로 들어가지 않고 어떻게 컴퓨터 비전이 만들어졌고 정의가 무엇인지부터 들어가려고 합니다.\n",
    "\n",
    "그 이유는 비전의  청사진으로 그려놓고 어떤 방향과 목적을 가지고 이 기술이 만들어졌는지 알아야 조금 더 컴퓨터 비전의 매력을 빠질 수 있다고 생각하기 때문입니다.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Computer Vision 정의\n",
    "\n",
    "시각 데이터에 대해 인식하고 추론하는 인공시스템을 구축하는 연구를 의미합니다. 그리고 시각데이터는 우리가 아는 이미지부터 동영상 그리고 의료사진까지 광범위하게 포괄합니다. \n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/f59e5f7c-d29c-4278-a891-6bb2ad04b9e1/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Computer Vision과 Deep learning\n",
    "\n",
    "다양한 방식으로 컴퓨터 비전을 활용한 기술을 쓰고 있으면 그로 인해 엄청난 데이터들이 쌓일 것이고 그것들 사람이 하나 하나 볼 수는 없을 것입니다.\n",
    "\n",
    "예를들어, 인스타그램은 하루에 100만장 정도의 사진이 업로드됩니다. 이 수 많은 사진들을 인스타그램회사 직원이 하나씩 확인해서 업로드를 가능하게 해주는 걸까요? 그렇지 않습니다. \n",
    "\n",
    "어떠한 기술을 통해서 다양하고 많은 데이터를 처리할 수 있을까요?\n",
    "\n",
    "\n",
    "그것은 바로 딥러닝 기술을 이용하는 것이고 딥러닝 기술을 큰 범주에서 설명하면 사람의 사고방식을 컴퓨터에게 가르치는 기계학습 분야입니다. \n",
    "\n",
    "*여기서 말하는 사고방식을 주로 사람이 생각을 할 때 꼬리에 꼬리를 무는 계층적 사고방식입니다*\n",
    "\n",
    "딥러닝과 컴퓨터비전의 접점이 무엇인지 벤다이어그램을 통해서 직관적으로 알려드립니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/ae32768f-cb99-40c4-aea5-2efedc142800/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "\n",
    "저희가 주로 다룰 것은 컴퓨터 비전쪽이지만 이번 블로그에서는 청사진을 그리는 것이 목적이기에 빨간색 부분을 중점으로 이야기를 해볼까합니다. 이제, 딥러닝과 컴퓨터 비전의 역사에 대해서 이야기를 하겠습니다.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## History of Computer Vision \n",
    "\n",
    "역사 이야기라서 조금은 지루할 수도 있지만, 모든 기술은 실험 과정과 그로 인해 얻어진 깨달음을 토대로 만든 것이기에 흐름을 아는 것이 중요합니다.\n",
    "\n",
    "1959년, Hubel 과 Wiesel가 첫 Computer Vision 연구가 시작이 되었습니다. \n",
    "\n",
    "물론 컴퓨터 비전 목적의 연구보단 뇌과학 연구이긴 하였지만 연구 과정은 고양이의 뇌가 시각적 자극에 어떻게 반응을 하는지 관찰하고 \n",
    "\n",
    "이 과정에서 simple cell이 간단한 자극에 반응하고 이 반응들이 모여 complex cell이 되어 복잡한 자극에  반응을 한다는 것을 알게되었고 이것은 훗날 vision works로 불리게 됩니다.\n",
    "\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/9e0ef6fd-adcd-4337-8722-aca7b65df048/image.png)\n",
    " \n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "1963년, Larry Roberts는 실제로 사진 정보를 얻는 방법인, 시각적 데이터를 컴퓨터가 이해하기 쉽도록 기하하적 처리 시도합니다.\n",
    "\n",
    "이 시도를 통해서 지금의 CNN기술에서 features를 추출하여 object detection기술이 착안 되었다고 생각이 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/4cf5aa14-3c12-45aa-a6a2-016d3b70edea/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "1970년, David Marr는 시각적 표현 단계에 대한 아이디어 제안으로, 이미지를 3D로 표현하기 시작합니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/bbc12f00-fc74-4fa4-9afd-1d95e3cd5602/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "\n",
    "\n",
    "#### 1970s, 인기주제는 Parts를 이용하여 인식\n",
    "\n",
    "Object Recognition연구가 시작이 됩니다. \n",
    "\n",
    "주로, Pictorial Structure와 Generalizaed Cylinder처리하는 컴퓨터 시스템을 구축하여 사람을 인식하는 수준으로 도달하고 싶었지만 하드웨어의 성능의 수준 미달로 되지 못하게 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/9d2ddb5b-b6e1-4d0f-85fb-66546d16e18a/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "\n",
    "\n",
    "#### 1980s, 인기 주제는 Edge Detection활용\n",
    "\n",
    "컴퓨터 하드웨어의 성능 증가로 실제 이미지가 인식이 되고 구현이 가능해져서 관련 연구가 시작이 됩니다.\n",
    "\n",
    "\n",
    "1986년, John Canny는  이미지 속 엣지와 이미지를 탐색하는 알고리즘을 구축합니다.\n",
    "\n",
    "1987년, David Lowe는 이미지의 edges를 edge matching기술을 이용하여 object recognition 하는 원리를 제시하게 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/cfbfb389-5fab-4dec-9ee5-2a47589b2f4c/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "\n",
    "\n",
    "#### 1990s  인기 주제는 그룹핑을 통해서 물체를 인식\n",
    "\n",
    "더 쉽게 레이블을 전달하거나 인식이 가능해졌고 그로 인해 어떻게 하면 더 복잡한 이미지와 장면을 만들 수 있을지에 대한 고민들이 주를 이루게 됩니다.\n",
    "\n",
    "1997년 Normalized Cuts, Shi and Malik는 엣지를 매칭하는 것이 아닌 입력 이미지를 image segmentation 기법을 적용합니다. \n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/2f979b31-ffe9-438a-a53b-e9bfc6c3c43e/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "\n",
    "\n",
    "#### 2000s 인기 주제는 매칭기법을 활용하여 물체인식\n",
    "\n",
    "2000s 머신러닝의 활용도가 급증하게 되는 기점이어서 시각적 인지 시스템과 detection분야의 성능 향상 또한 증가합니다.\n",
    "\n",
    "1999년 SIFT, David Lowe는  input image가 들어오면 작은 key point들을 인식한 후 특성 벡터를 이용하여 외관에 matching을 시키면 밝기나 각도가 바뀌어도 object를 detection연구가 진행이 된다는 걸 밝혀냅니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/c1ec4ac9-8d50-45bd-8d05-533b16a46f9e/image.png)\n",
    "\n",
    "[저자: Justin Jhonson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "2001년 Viola and Jones이  우리가 아는 머신러닝 기반으로 얼굴 이미지를 인식하는 알고리즘(Face Detection)과 Boosted Decision Tree을 통해서 얼굴을 인식을 합니다. \n",
    "\n",
    "대표적인 예시로, 저희가 카메라로 사람을 찍을 때  노란색 박스가 뜨는데 그것이 바로 Face Detection입니다.\n",
    "\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/d527970c-f8b8-4760-9383-2d0871296073/image.png)\n",
    "\n",
    "[저자: AZMATH MOOSA ]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://www.baseapp.com/computer-vision/understanding-face-recognition-technology/)]\n",
    "\n",
    "Computer Vision의 정확성을 높이기 위해서는 당연히 수 많은 데이터가 필요하고 그 데이터를 저장하고 업로드할 수 있는 데이터 창고가 점점 필요한 시기가 다가오게 됩니다.\n",
    "\n",
    "2009년 이러한 수 많은 필요성이 부각이 되면서 ImageNet이라는 데이터 창고가 완성이 되어서 배포가 가능해졌고 다양하고 방대한 데이터가 기반이 되니 여러 기술을 적용할 수 있게 되었고 그로 인해 Image Classification Challenge라는 시대를 열게 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/1dfb7d66-598c-498c-bf1a-bba63a46a6b0/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]\n",
    "\n",
    "Image Classification Challenge는 2010부터 시작이 되었고 아래 사진은 우승자의 정확도인데 2012년 이전에는 개선 폭이 크지 않았다가  AlexNet이라는 네트워크의 도입으로 개선이 확 되어서 사람보다 더 정확한 결과를 낼 수 있는 수준까지 오게 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/bace3aaa-7683-453e-8d71-7b9f18885ef5/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture01.pdf)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
