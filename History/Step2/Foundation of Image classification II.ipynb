{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affected-shell",
   "metadata": {},
   "source": [
    "## Image Classification with Block\n",
    "\n",
    "이제부터 어떻게 Image Classification이 여러 연구 분야에서 어떻게 쓰이는지 알아보는데 이 기술은 단독으로 쓰이는 것보다 다른 작업을 구성하는 하나의 block형태로 자주 쓰입니다.\n",
    "\n",
    "#### Object Detection(물체 탐색)\n",
    "\n",
    "Object Detection은 이미지 안에 있는 객체를 박스로 그려서 가둔 후 그 이미지가 무엇인지 예측하는 것으로 \n",
    "\n",
    "\n",
    "Image Classification과 같이 쓰면 이미지 속 각 물체가 어디에 위치했는지를 표현하는 것으로 박스 옮겨 가며 Sliding Window라는 작업을 수행하며 물체 탐색를 합니다.\n",
    "\n",
    "*Sliding window는 사진을 윈도 사이즈에 맞춰 나눈 다음 매 윈도우로 잘린 이미지를 입력값으로 모델을 통과해서 결과를 얻는 방법입니다.*\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/79141f57-e49f-4a6f-a60b-ea8d45d279e8/image.png)\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/2023ca1c-abd0-42c0-b55d-49b337cf406a/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "#### Image Captioning(이미지 캡션)\n",
    "\n",
    "Image Captioning은 문자 그대로 이미지를 하나의 인지적 언어로 바꿔주는 것으로 예를 들면, 남자 사진을 보고 man으로 출력하는 것입니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/faffc694-66b7-4905-9c0d-2b8d43dc4ef2/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "#### Playing Go\n",
    "\n",
    "컴퓨터 게임을 할 때도 AI 시스템이 들어가는데 그 중 Image Classification 기술 또한 도움을 줍니다.\n",
    "\n",
    "바둑으로 예를 들면, AI는 좌표를 픽셀 값으로 받은 후Image Classification을 이용하여 바둑돌이 놓인 위치를 인식할 수 있게 됩니다.(알파고를 연상하시면 편합니다.)\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/87c652e3-b52a-43b9-8f6f-83658742ed6e/image.png)\n",
    "\n",
    "[저자: Screenshot by Claire Reilly/CNET]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://www.cnet.com/news/google-deepmind-hooked-us-on-go-the-geekiest-game-youve-never-heard-of/)]\n",
    "\n",
    "\n",
    "\n",
    "#### Code\n",
    "\n",
    "위의 여러 가지 기능 뿐만 아니라 더욱 영향력이 있게 Image classification을 이용하여 기술 구현이 가능합니다.\n",
    "\n",
    "허나, 다양한 상황이 있기에 정석적인 알고리즘 코드가 없다는 것이 어려운 부분이긴 하지만 다르게 이야기하면 그만큼 연구가 활발하게 진행이 되어야하는 부분이기도 합니다.\n",
    "\n",
    "\n",
    "---  \n",
    "\n",
    "#### Edges\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/2717f1bf-b9a1-432d-b6fe-d4bb0c8143e1/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 제출: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "Edges를 통해서 이미지를 분류할 수 있으면 좋겠지만 실제로는 그렇지 못하는 이유는 위의 Problems뿐만 아니라 여러 무한한 경우의 수로 인해 같은 이미지도 다르게 인지와 인식을 할 수 있게 됩니다. \n",
    "\n",
    "그래서 저희는 방대한 경우의 수를 대비하여 만든 데이터 셋이 필요했습니다.\n",
    "\n",
    "### Data-Driven Approach\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/bc7b8ce5-a8b2-4d0c-9a49-cd7c441c0e3b/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "머신러닝 기반으로 만든 데이터 저장소입니다. 컴퓨터에 데이터와 그에 관한 레이블(정답값)만 학습을 시켜서 특징을 추출하면 나중에 새로운 데이터가 들어와도 알아서 특징을 잡아낼 수 있기에 적절한 분류가 가능해집니다.\n",
    "\n",
    "프로그래머는 기계를 어떻게 학습시키고 결과처리할지에 대한 알고리즘만 구현하면 되기에 편합니다.\n",
    "\n",
    "이러한 이유를 바탕으로 머신러닝을 잘 조작하면, 원하는 종류의 사진을 분류하고 판단하는 Generic Program을 만들 수 있게됩니다.\n",
    "\n",
    "*Generic Program은 사용자가 원하는 작업을 수행하는 컴퓨터 프로그램을 찾아내는 방식입니다.*\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Image Classification Datasets of Generic Program \n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/204d4757-d3e7-421a-be8e-68c06b3851d3/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "이 부분은 그저 이러한 데이터가 있고 이렇게 구성이 되어있다 정도만 이해하고 넘어가셔도 됩니다.\n",
    "\n",
    "#### MNIST\n",
    "\n",
    "1980~1990년대 CV에서 글자인식 프로그램을 테스트할 때 직접 사용된 데이터이지만 너무 단순한 데이터이기에 실생활에서 유용한지는 의문입니다.\n",
    "\n",
    "데이터 구성\n",
    "\n",
    "- Classes: 10개, Digits 0 ~ 9\n",
    "\n",
    "- Grayscale Images: 28X28\n",
    "\n",
    "- Training Images: 50K\n",
    "\n",
    "- Test Images: 10K\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/6854e2e7-2275-409c-b0f4-1f4d0e1c8ffe/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "#### CIFAR 10 & CIFAR 100\n",
    "\n",
    "MNIST보단 복잡한 데이터셋이지만 머신러닝 모델 증명하기에는 부족하고 토이 프로젝트할 때 주로 쓰입니다.\n",
    "\n",
    "\n",
    "##### CIFAR 10\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/040190fd-34a7-4da2-98dc-11ccb640bfd0/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "데이터 구성\n",
    "\n",
    "- Classes: 10개\n",
    "\n",
    "- Training Images: 50K (5K per class)\n",
    "\n",
    "- Test images: 10K (1K per class)\n",
    "\n",
    "- Images: 32X32 RGB\n",
    "\n",
    "##### CIFAR100\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/8c764eb1-fa5b-4585-aac8-94894079f25c/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "데이터 구성\n",
    "\n",
    "- classes : 100개\n",
    "\n",
    "- Training\timages: 50K (500 per class)\n",
    "\n",
    "- Testing\timages: 10K (100\tper\tclass)\n",
    "\n",
    "- Images: 32x32\tRGB\n",
    "\n",
    "- Superclasses : 20개\n",
    "\n",
    "\n",
    "#### ImageNet\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/9f457b9b-545a-4566-9568-7f35da704d70/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "Object분야에서 표준 데이터라 할 수 있을 정도로 머신러닝 모델의 성능을 보여줄려면 필수로 사용하고 이미지 크기는  원하는 크기의 이미지를 받을 수 있지만 보통256 X 256 크기를 사용합니다.\n",
    "\n",
    "그리고 이미지에서 보통 1개의 object만 존재하지 않기에 보통 top 5 accuracy라는 방식을 이용합니다.\n",
    "\n",
    "데이터 구성\n",
    "\n",
    "- Classes: 1000\n",
    "\n",
    "- Training images : ~ 1.3M training images(~1.3K per class)\n",
    "\n",
    "- Validation Images: 50K (50 per class)\n",
    "\n",
    "- Test Images : 100K (100 per class)\n",
    "\n",
    "#### MIT Places\n",
    "\n",
    "이름 그대로 배경 유형에 집중한 데이터 셋입니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/4de07c0a-d6b7-4224-ab0e-ca6e5a258106/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "데이터 구성\n",
    "\n",
    "- Class : 365개의 다른 배경\n",
    "\n",
    "- Train images: ~8M\n",
    "\n",
    "- Val images: 18.25K( 50 per class)\n",
    "\n",
    "- Test images: 32.5K (900 per class)\n",
    "\n",
    "- Image size: 265X256\n",
    "\n",
    "#### Omniglot\n",
    "\n",
    "카테고리별로 20개 정도 밖에 안되는 작은 데이터 셋이지만 머신러닝 모델이 적은 수의 데이터에 잘 작동하는지 확이할 때 사용합니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/50d8d9c1-0c3f-4bc8-9c56-b5cb6141d7d7/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "- Categories: 1623개 (50개의 다른 알파벳)\n",
    "\n",
    "---\n",
    "\n",
    "### Nearest Neighbor (NN)\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/e5c4a6da-74c1-4779-8b16-06595973f5ba/image.png)\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://discourse.mcneel.com/t/traveling-salesman-problem-nearest-neighbor-heuristic/109271)]\n",
    "\n",
    "Machine Learning Algorithm of Image Classification\n",
    "부분에서 가장 간단한 알고리즘입니다. \n",
    "\n",
    "왜냐하면, 훈련 과정에서 훈련 데이터를 저장하고 예측 과정에서는 예측 이미지를 입력해서 사전에 저장한 훈련 데이터와 가장 유사한 이미지를 찾고 그 레이블을 리턴하는 구조입니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/6d2b49de-b041-4a90-b487-a07ac9078001/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "즉, 암기를 잘해서 잘 맞추는 분류기를 만드는 것이다.\n",
    "이 암기를 잘하려면 이미지 간의 유사성을 잘 파악해야하고 이 유사성의 판별 기준은 거리 행렬을 통해서 이미지를 비교하는 것이다.\n",
    "\n",
    "대표적인 예로, L1 distance를 뽑을 수 있고 L1 distance의 값이 작을 수록 유사하다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/278b5118-03da-42a8-aa2e-760afd3861d8/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "#### Mechanism of NN\n",
    "\n",
    "\n",
    "\n",
    "시간 복잡도는 문제를 걸리는 시간과 함수의 관계를 나타내는 것입니다.\n",
    "\n",
    "\n",
    "훈련 과정에서 포인터 같은 매커니즘 이용 시 O(1)이 쓰입니다.\n",
    "\n",
    "*0(1): 입력값이 아무리 커도 실행 시간은 일정해서 최고의 알고리즘입니다.\n",
    "\n",
    "테스트 과정에선 모든 데이터를 다 봐야하므로 O(N)만큼 시간이 걸리게 됩니다\n",
    "\n",
    "*O(n): 입력값만큼 실행 시간에 영향을 받으며, 알고리즘을 수행하는 데 걸리는 시간은 입력값에 비례합니다.\n",
    "\n",
    "이로 인해서 예측 과정에서 시간이 너무 오래 걸려서 좋은 모델이라고 평가를 받지 못합니다.\n",
    "\n",
    "\n",
    "#### NN 분류기의 결과\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/3ee843ae-44e7-4014-8af0-5c0905355cce/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "위 사진은 NN 과 L1 distance를 적용한 이미지 분류기가 추출한 결과를 의미하는 것으로 제대로 인식한 것은 4개에 불과하고 나머지는 전혀 다르게 인지한 것입니다.\n",
    "\n",
    "결론은 이미지의 유사도를 L1 distance로만 구하는 NN은 이미지를 정확하게 분류하지 못한다는 것입니다.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Decision Boundaries(결정영역)\n",
    "\n",
    "결정 영역으로 NN기반으로 수행하는 것으로 같은 카테고리에 속한 것을 묶어서 집합을 구성합니다.\n",
    "\n",
    "여러 집합들이 생기고 그 집합 간의 영역을 그어서 예측 데이터를 넣을 시, 해당 데이터 영역의 카테고리가 데이터의 카테고리가 되는 방식입니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/514656f3-1f57-478c-bf3d-2da3d691bca9/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "*점: 훈련 이미지. 배경: 테스트 카테고리영역\n",
    "\n",
    "즉, 사진에서와 같이 파란색 데이터를 넣으면 파란색 영역으로 빨간색 데이터를 넣으면 빨간색 영역으로 가는 것이지만 간혹 특정 영역에서 튀어나오거나 동떨어지는 노이즈가 발생합니다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### K Nearest Neighbor (KNN)\n",
    "\n",
    "*K: 주변 개수\n",
    "\n",
    "Decision Boundaries에서 노이즈로 인해서 이상한 점이 하나 생겼을 겁니다 그것을 해결하기 위한 방식으로 주변에 있는 점들을 K개 만큼 봐서 가장 많은 것을 골라내는 것입니다. \n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/0cc7c4ce-31c0-42e0-a75f-7f8576c2294e/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "또한 다른 데이터와 동떨어져서 생기는 이상치도 해결이 가능합니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/d31ab91d-8e2d-48b0-b82a-6409c4338ebf/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "물론 이로 인해 어느 카테고리도 정해지지 않은 공백 지역이 생깁니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/9ea82ba6-f28f-45bd-b4a0-9795c9aec144/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "그러므로 K개를 엄청 크게 늘릴수 없기에 최적의 K를 찾기 위해서 계속 연구 중입니다.\n",
    "\n",
    "\n",
    "#### Distance Metrics\n",
    "\n",
    "NN이야기할 때 배웠던 거리 행렬을 기억하시나요? 결정영역은 거리 행렬에 따라서 모양이 조금씩 달라지는데 2차원 데이터에서 L1 사용 시 수직이나 수평과 평행하게 45각도를 이루지만 L2를 사용하면 제약없이 형성이 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/9f9b04cf-63be-4cfe-b4e9-e1227d0e0431/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "이렇게 단편적으로만 보면 L2가 가장 좋아보일 수 있지만 상황에 따라 L1이 좋을 때도 있어서 상황에 따라 맞게 잘 사용해야 합니다. \n",
    "\n",
    "그러나 하나 확실한 것은 적절한 거리 행렬과 KNN 알고리즘을 이용하면 어떤 데이터가 들어와도 좋은 결과를 나타낼 수 있게 됩니다.\n",
    "\n",
    "*거리행렬과 모델을 설정하여 실제로 직관적 실습을 할 수 있는 코드 입니다.\n",
    "\n",
    "http://vision.stanford.edu/teaching/cs231n-demos/knn/\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "이제는 하이퍼파라미터라는 인공지능에서 가장 중요하고 필요한 것을 배우게 되니 집중해주시길 바랍니다.\n",
    "\n",
    "중요한 이유는 모델이 learning을 할 때 효과를 좋게 하는 변수이기 때문입니다.\n",
    "\n",
    "Hyperparameter란 학습 데이터를 통해서 Training을 하는 것이 아닌 사전에 미리 정한 parameter를 말하고 보통 모든 경우를 포괄하는 최적해는 존재하지 않게 됩니다.\n",
    "\n",
    "그래서 Hyperparameter을 정할 때는 직접 값을 변경하면서 해본 후에 최고의 parameter 선택해야합니다.\n",
    "\n",
    "*parameter은 서브 인풋 같은 것입니다.*\n",
    "\n",
    "예시를 들자면, KNN의 K값과 distance metric입니다.\n",
    "\n",
    "\n",
    "### Hyperparmeter선택 방법\n",
    "\n",
    "#### 주어진 데이터에 가장 적합한 하이퍼파라미터 정하기\n",
    "\n",
    "직관적으로 보기엔 가장 좋아보이지만 예측을 해야하는 상황에선 사전 훈련 데이터에 없던 것으로 입력 데이터가 들어오면 잘 작동할 수 없고 노이즈 문제에서도 자유롭지 못합니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/c1505f74-9d37-43db-b9b6-2c632560138d/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "\n",
    "#### 데이터를 학습(train) 과 실험(test)로 나눈 후에 학습\n",
    "\n",
    "\n",
    "데이터로 모델 학습시켰을 시에 실험 데이터를 예측했을 때 최고의 결과를 내는 방식입니다.\n",
    "\n",
    "맨 처음 방식보다는 좋을 수 있지만 결국 실험 데이터에만 의존을 하는 결과를 내기에 너무 이상하게 잘된 현상인 overfitting을 불러 일으킬 수 있습니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/6f04e7e9-9d8d-49f2-acf9-7347d996a3a3/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "#### 데이터를 train, validation, test로 나누는 방식\n",
    "\n",
    "모델을 먼저 훈련시킨 후 validation data을 통해서 제일 좋은 hyperparameter를 정한 후에 test를 하면 두번째 방식처럼 test data만 의존하지 않게 됩니다.\n",
    "\n",
    "그러므로 overfitting문제를 해결할 수 있게 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/428609b2-724c-488e-b6c4-a071d080ca32/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "#### 데이터와 data set을 train 과 test으로 나눈다음에 train을  한 번 더 여러개의 fold로 나누기\n",
    "\n",
    "그리고 fold를 번갈아가며 validation data로 정하면서 3번의 방식으로 진행이됩니다.\n",
    "\n",
    "이론적으로는 가장 좋으나 계산량이 너무 오래 걸려서 대규모에선 사용이 안됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/565c631d-0cb2-43bc-8e58-fe258b882653/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "###  KNN 근사치 찾기\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/b246381e-2104-4400-a71c-9def5598f2ae/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "KNN는 training sample이 많으면 많을수록 어떤 함수는 표현이 정밀하게 가능하게 됩니다. \n",
    "\n",
    "머신러닝 모델의 입력이 데이터이고, 출력은 예측값인 함수로도 표현이 가능하여 어느 문제던 처리가 가능하게 됩니다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### 차원의 저주\n",
    "\n",
    "우리가 데이터 차원이 커지고 데이터 양이 많아지면 무조건 좋을 것 같지만 실제로는 그렇지 않은 현상입니다.\n",
    "\n",
    "특정 data space를 모두 포괄하는 훈련셋이 차원이 증가할 때마다 지수적으로 증가하게 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/cd432dc5-234b-4970-b9a5-21655262cd4a/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "예를 들면, 32 X 32크기의 이진 이미지를 사용하는 경우 존재 가능한 이미지가 너무 크므로 이 이미지가 모든 공간을 감당할 데이터를 모으는 게 불가능하다는 것을 알게됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/08dc7bb8-873f-40b9-924c-b13fed3867f2/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "### KNN의 실용성\n",
    "\n",
    "데이터가 많으면 많을수록 KNN을 사용하지 않는데 왜냐하면 예측을 하는 시간도 너무 오래 걸리고 예측이 잘 되려면 \n",
    "\n",
    "너무나 많은 데이터 셋이 필요하게되어 차원의 저주에 빠지게 되기 됩니다.\n",
    "\n",
    "그리고 실험한 결과도 그렇게 유의미함을 나타내지 못하기도 합니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/03ee67c2-3be3-4232-b0ff-1dad2d119732/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "그러나 이러한 문제를 해결하는 방법을 알려드립니다.\n",
    "\n",
    "### 해결책\n",
    "\n",
    "입력 이미지 벡터를 바로 받지 않고 ConvNet을 적용시킨 후에 특성 벡터(feature vector)로 바꾸고 이를 KNN의 입력 데이터로 사용하면 유의미한 결과를 얻게 됩니다.\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/fa40d652-d205-4f68-87cc-866a938c2413/image.png)\n",
    "\n",
    "![](https://images.velog.io/images/qsdcfd/post/fef1d35a-92ad-4873-a14f-f302606e583f/image.png)\n",
    "\n",
    "[저자: Justin Johnson]\n",
    "\n",
    "[이미지 출처: [링크텍스트](https://web.eecs.umich.edu/~justincj/slides/eecs498/498_FA2019_lecture02.pdf)]\n",
    "\n",
    "---\n",
    "\n",
    "이번 블로그를 마치려고 합니다. 우리는 지금까지 이미지 분류에 대한 전반적인 큰 틀을 배웠고 다음에는 Linear classifier을 배울 겁니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-album",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
